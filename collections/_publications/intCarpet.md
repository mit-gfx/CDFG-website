---
acknowlegement: We are grateful to all volunteers for their contributions to our dataset and R. White for the administration of the project. We thank the anonymous reviewers for their insightful comments.
authors: Yiyue Luo, Yunzhu Li, Michael Foshey, Wan Shou, Pratyusha Sharma, Tom√°s Palacios, Antonio Torralba, Wojciech Matusik
featured_image: /assets/images/Luo_CVPR2021.png
layout: publication
publication: CVPR
publication_link: /assets/files/Luo_CVPR2021.pdf
project_website: http://intcarpet.csail.mit.edu/
title: 'IntelligentCarpet: Inferring 3D Human Pose from Tactile Signals'
date: 2021-06-24 12:00:00 -0700
---

Daily human activities, e.g., locomotion, exercises, and resting, are heavily guided by the tactile interactions between human and the ground. In this work, leveraging such tactile interactions, we propose a 3D human pose estimation approach using the pressure maps recorded by a tactile carpet as input. We build a low-cost, high-density, large-scale intelligent carpet, which enables the real-time recordings of human-floor tactile interactions in a seamless manner. We collect a synchronized tactile and visual dataset on various human activities. Employing state-of-the-art camera-based pose estimation model as supervision, we design and implement a deep neural network model to infer 3D human poses using only the tactile information. Our pipeline can be further scaled up to multi-person pose estimation. We evaluate our system and demonstrate its potential applications in diverse fields.
